# Muscle Segmentation in MSOT images


*Abbreviations*:

*AL: Active Learning, MSOT: Multispectral Optoacoustic Tomography Images, ROI: Region of Interest, MC-dropout: Monte-Carlo dropout,CNN: Convolutional Neural Network, FCN: Fully Convolutional Network*

This project aims at the Segmentation of Muscle Tissue in MSOT images.

For this purpose, an Active Deep Learning framework was be used. AL is a technique that aims at maximizing a network's performance, while at the same time minimizing the total number of annotated data needed for training the model. Thus, a close-to-the baseline performance can be achieved by using just a subset of the data that the algorithm would usually train with, reducing significantly the total time needed for training and alleviating the burden of data annotation from the side of the clinicians. 

In our case, the baseline behavior was established on a UNET architecture, slightly altered by introducing batch normalization layers first, and by subsequently adding dropout layers to incorporate Uncertainty Estimation. Therefore, the technique of Monte Carlo dropout was used. MC-dropout approximates a Bayesian Neural Network by sampling from a neural network trained with dropout at inference time in order to produce a distribution over the outputs. Its mathematical formulation suggests that an uncertainty map can be generated by sampling T times from the network at test time and by then computing the entropy across all classes. [T. DeVries and G. W. Taylor. Leveraging Uncertainty Estimates for Predicting Segmentation Quality.] 

The dataset is split into training, validation and test set, like in every traditional deep learning algorithm. A further split of the training set into annotated- and unannotated pool with a 10-90% ratio sets the initial samples for the AL framework. In our approach, all data were annotated in advance by a clinician, however, when we refer to the unannotated we will assume that their respective ground truths are still unknown to the model. The proposed network pipeline will be trained on the annotated data and evaluated on the unannotated data in an iterative scheme, whose goal is to yield at the end of every iteration the k most informative samples to be annotated (or in our case to be chosen with their respective ROIs) and added to the training set for the next iteration. In our approach, steps of 10% were followed until reaching the 50% of the training data. 

The proposed framework consists of the following components: Initially a variation of UNET with MC-dropout layers (p=0.5) is responsible for producing: a segmentation mask and an uncertainty mapping. Subsequently, a second CNN was implemented, aiming at predicting a quality estimation of the model by being evaluated on the remaining unannotated data and predicting their dice coefficients. The selection of the to-be-added samples is based on this dice score estimation, namely the data samples corresponding to the 10% of the worst dice indices are selected and added to the training set together with their respective ROIs. Based on their role, the network components were named: UNet_mc and DiceNet respectively.

**Evaluation metrics**:

The Dice Coefficient metric is being used for evaluation of UNET and the mean squared error (mse) for the vgg-like CNN.
